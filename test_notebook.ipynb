{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Biomedicine Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model imports\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# backbone imports\n",
    "from backbones.blocks import Conv2d_fw, BatchNorm2d_fw, init_layer, Flatten, SimpleBlock, BottleneckBlock\n",
    "from backbones.resnet import ResNet, ResNet10\n",
    "from backbones.fcnet import FCNet, EnFCNet\n",
    "\n",
    "# run imports\n",
    "from hydra.utils import instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Block definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, dilation=1, groups=1, bias=True):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.dilation = dilation\n",
    "        padding = dilation * (kernel_size - 1)\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, stride,\n",
    "                                padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Takes something of shape (N, in_channels, T),\n",
    "        # returns (N, out_channels, T)\n",
    "        out = self.conv1d(input)\n",
    "        return out[:, :, :-self.dilation] # TODO: make this correct for different strides/padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 11])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.randn(16, 256, 11)\n",
    "conv = CausalConv1d(256, 128, kernel_size=2, dilation=2)\n",
    "out = conv(batch)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, dilation, filters, kernel_size=2):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.casualconv1 = CausalConv1d(in_channels, filters, kernel_size, dilation=dilation)\n",
    "        self.casualconv2 = CausalConv1d(in_channels, filters, kernel_size, dilation=dilation)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is dimensions (N, in_channels, T)\n",
    "        xf = self.casualconv1(input)\n",
    "        xg = self.casualconv2(input)\n",
    "        activations = F.tanh(xf) * F.sigmoid(xg) # shape: (N, filters, T)\n",
    "        return torch.cat((input, activations), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 384, 11])\n"
     ]
    }
   ],
   "source": [
    "dense = DenseBlock(256, 2, 128)\n",
    "out = dense(batch)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCBlock(nn.Module):\n",
    "    def __init__(self, in_channels, seq_length, filters):\n",
    "        super(TCBlock, self).__init__()\n",
    "        self.dense_blocks = nn.ModuleList([DenseBlock(in_channels + i * filters, 2 ** (i+1), filters)\n",
    "                                           for i in range(int(math.ceil(math.log(seq_length, 2))))])\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is dimensions (N, T, in_channels)\n",
    "        input = torch.transpose(input, 1, 2)\n",
    "        for block in self.dense_blocks:\n",
    "            input = block(input)\n",
    "        return torch.transpose(input, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape: torch.Size([16, 11, 256])\n"
     ]
    }
   ],
   "source": [
    "batch = batch.permute(0, 2, 1)\n",
    "print(f\"batch shape: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape: torch.Size([16, 11, 768])\n"
     ]
    }
   ],
   "source": [
    "tc = TCBlock(256, 11, 128)\n",
    "out = tc(batch)\n",
    "print(f\"out shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, key_size, value_size):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.linear_query = nn.Linear(in_channels, key_size)\n",
    "        self.linear_keys = nn.Linear(in_channels, key_size)\n",
    "        self.linear_values = nn.Linear(in_channels, value_size)\n",
    "        self.sqrt_key_size = math.sqrt(key_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input is dim (N, T, in_channels) where N is the batch_size, and T is\n",
    "        # the sequence length\n",
    "        mask = np.array([[1 if i>j else 0 for i in range(input.shape[1])] for j in range(input.shape[1])])\n",
    "        mask = torch.BoolTensor(mask)\n",
    "\n",
    "        #import pdb; pdb.set_trace()\n",
    "        keys = self.linear_keys(input) # shape: (N, T, key_size)\n",
    "        query = self.linear_query(input) # shape: (N, T, key_size)\n",
    "        values = self.linear_values(input) # shape: (N, T, value_size)\n",
    "        temp = torch.bmm(query, torch.transpose(keys, 1, 2)) # shape: (N, T, T)\n",
    "        temp.data.masked_fill_(mask, -float('inf'))\n",
    "        temp = F.softmax(temp / self.sqrt_key_size, dim=1) # shape: (N, T, T), broadcasting over any slice [:, x, :], each row of the matrix\n",
    "        temp = torch.bmm(temp, values) # shape: (N, T, value_size)\n",
    "        return torch.cat((input, temp), dim=2) # shape: (N, T, in_channels + value_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape: torch.Size([16, 11, 384])\n"
     ]
    }
   ],
   "source": [
    "attn = AttentionBlock(256, 128, 128)\n",
    "out = attn(batch)\n",
    "print(f\"out shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnailFewShot(nn.Module):\n",
    "    def __init__(self, N, K, backbone, use_cuda=False):\n",
    "        # N-way, K-shot\n",
    "        super(SnailFewShot, self).__init__()\n",
    "        self.encoder = backbone\n",
    "        num_channels = 64 + N # change with actual backbone output size\n",
    "        \n",
    "        num_filters = int(math.ceil(math.log(N * K + 1, 2)))\n",
    "        self.attention1 = AttentionBlock(num_channels, 64, 32)\n",
    "        num_channels += 32\n",
    "        self.tc1 = TCBlock(num_channels, N * K + 1, 128)\n",
    "        num_channels += num_filters * 128\n",
    "        self.attention2 = AttentionBlock(num_channels, 256, 128)\n",
    "        num_channels += 128\n",
    "        self.tc2 = TCBlock(num_channels, N * K + 1, 128)\n",
    "        num_channels += num_filters * 128\n",
    "        self.attention3 = AttentionBlock(num_channels, 512, 256)\n",
    "        num_channels += 256\n",
    "        print(f\"final num_channels: {num_channels}\")\n",
    "        self.fc = nn.Linear(num_channels, N)\n",
    "        self.N = N\n",
    "        self.K = K\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "    def forward(self, input, labels):\n",
    "        x = self.encoder(input)\n",
    "        # print(f\"x shape after encoding: {x.shape}\")\n",
    "        batch_size = int(labels.size()[0] / (self.N * self.K + 1))\n",
    "        last_idxs = [(i + 1) * (self.N * self.K + 1) - 1 for i in range(batch_size)]\n",
    "        labels[last_idxs] = torch.Tensor(np.zeros((batch_size, labels.size()[1])))\n",
    "        if self.use_cuda:\n",
    "            labels[last_idxs] = labels[last_idxs].cuda()\n",
    "        x = torch.cat((x, labels), 1)\n",
    "        x = x.view((batch_size, self.N * self.K + 1, -1))\n",
    "        x = self.attention1(x)\n",
    "        x = self.tc1(x)\n",
    "        x = self.attention2(x)\n",
    "        x = self.tc2(x)\n",
    "        x = self.attention3(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "n_examples = 3\n",
    "n_query = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info = {\n",
    "    '_target_': 'datasets.cell.tabula_muris.TMSetDataset',\n",
    "    'n_way': n_classes,\n",
    "    'n_support': n_examples,\n",
    "    'n_query': n_query,\n",
    "}\n",
    "#train_batch = 16\n",
    "#val_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  self.adata.obs['label'] = pd.Categorical(values=truth_labels)\n",
      "/Users/maxconti/anaconda3/envs/dlb_project/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/datasets/cell/utils.py:66: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  self.adata.obs['label'] = pd.Categorical(values=truth_labels)\n",
      "/Users/maxconti/anaconda3/envs/dlb_project/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = instantiate(ds_info, mode='train')\n",
    "train_loader = train_dataset.get_data_loader()\n",
    "\n",
    "val_dataset = instantiate(ds_info, mode='val')\n",
    "val_loader = val_dataset.get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_one_hot(opt, labels):\n",
    "    #if opt.cuda:\n",
    "    #    labels = labels.cpu()\n",
    "    labels = labels.numpy()\n",
    "    unique = np.unique(labels)\n",
    "    map = {label:idx for idx, label in enumerate(unique)}\n",
    "    idxs = [map[labels[i]] for i in range(labels.size)]\n",
    "    one_hot = np.zeros((labels.size, unique.size))\n",
    "    one_hot[np.arange(labels.size), idxs] = 1\n",
    "    return one_hot, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_for_few_shot(opt, x, y):\n",
    "    seq_size = opt[\"num_cls\"] * opt[\"num_samples\"] + 1\n",
    "    print(f\"batch_for_few_shot: x.shape: {x.shape}, y.shape: {y.shape}, seq_size: {seq_size}\")\n",
    "    one_hots = []\n",
    "    last_targets = []\n",
    "    for i in range(opt[\"batch_size\"]):\n",
    "        if (i + 1) * seq_size > y.shape[0]:\n",
    "            break\n",
    "        one_hot, idxs = labels_to_one_hot(opt, y[i * seq_size: (i + 1) * seq_size])\n",
    "        print(f\"one_hot: {one_hot}, idxs: {idxs}\")\n",
    "        one_hots.append(one_hot)\n",
    "        last_targets.append(idxs[-1])\n",
    "    last_targets = Variable(torch.Tensor(last_targets).long())\n",
    "    one_hots = [torch.Tensor(temp) for temp in one_hots]\n",
    "    y = torch.cat(one_hots, dim=0)\n",
    "    x, y = Variable(x), Variable(y)\n",
    "    if opt[\"cuda\"]:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        last_targets = last_targets.cuda()\n",
    "    return x, y, last_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(last_model, last_targets):\n",
    "    _, preds = last_model.max(1)\n",
    "    acc = torch.eq(preds, last_targets).float().mean()\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_one_hot(opt, labels):\n",
    "    #if opt.cuda:\n",
    "    #    labels = labels.cpu()\n",
    "    labels = labels.numpy()\n",
    "    unique = np.unique(labels)\n",
    "    map = {label:idx for idx, label in enumerate(unique)}\n",
    "    idxs = [map[labels[i]] for i in range(labels.size)]\n",
    "    one_hot = np.zeros((labels.size, unique.size))\n",
    "    one_hot[np.arange(labels.size), idxs] = 1\n",
    "    return one_hot, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_map(labels):\n",
    "    labels = labels.numpy()\n",
    "    unique = np.unique(labels)\n",
    "    map = {label:idx for idx, label in enumerate(unique)}\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 21, value: 0\n",
      "key: 23, value: 1\n",
      "key: 39, value: 2\n",
      "key: 48, value: 3\n",
      "key: 52, value: 4\n"
     ]
    }
   ],
   "source": [
    "support_labels = y[:, :5].flatten() # N * K labels that are fixed for each sequence\n",
    "label_map = get_label_map(support_labels)\n",
    "for k, v in label_map.items():\n",
    "    print(f\"key: {k}, value: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hots(labels, map):\n",
    "    labels = labels.numpy()\n",
    "    idxs = [map[labels[i]] for i in range(labels.size)]\n",
    "    one_hot = np.zeros((labels.size, len(map)))\n",
    "    one_hot[np.arange(labels.size), idxs] = 1\n",
    "    return one_hot, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_batch(opt, x, y):\n",
    "    sequences = []\n",
    "\n",
    "    # get support set and labels\n",
    "    support_set = x[:, :opt[\"num_samples\"], :] # N x K samples that are fixed for each sequence\n",
    "    support_set = support_set.contiguous().view(-1, x.shape[2]) # flatten to get (N * K, input_dim)\n",
    "    # print(f\"support_set shape: {support_set.shape}\")\n",
    "    n_query = x.shape[1] - opt[\"num_samples\"]\n",
    "    support_labels = y[:, :opt[\"num_samples\"]].flatten() # N * K labels that are fixed for each sequence\n",
    "\n",
    "    # get label map\n",
    "    label_map = get_label_map(support_labels)\n",
    "\n",
    "    all_labels = []\n",
    "    pred_targets = []\n",
    "    for i in range(n_query):\n",
    "        for j in range(opt[\"num_cls\"]):\n",
    "            query_sample = x[j, opt[\"num_samples\"] + i, :].unsqueeze(0) # get a new query sample\n",
    "            seq = torch.cat((support_set, query_sample), dim=0) # sequence of N x K + 1 samples\n",
    "            # print(f\"seq shape: {seq.shape}\")\n",
    "            sequences.append(seq) # append to list of sequences\n",
    "            \n",
    "            last_seq_label = y[j, opt[\"num_samples\"] + i]\n",
    "            # seq_labels = support_labels + [last_seq_label]\n",
    "            seq_labels = torch.cat((support_labels, torch.Tensor([last_seq_label]).long())) # N x K + 1 labels\n",
    "            # labels, idxs = labels_to_one_hot(opt, seq_labels)\n",
    "            labels, idxs = get_one_hots(seq_labels, label_map)\n",
    "\n",
    "            all_labels.append(labels)\n",
    "            pred_targets.append(idxs[-1])\n",
    "\n",
    "    # sequences are of shape (n_query * n_cls, (N * K + 1), input_dim))\n",
    "    # all_labels are of shape (n_query * n_cls, (N * K + 1), num_cls)\n",
    "    # pred_tagets are of shape (n_query * n_cls)\n",
    "\n",
    "    labels = torch.Tensor(all_labels).view(-1, opt[\"num_cls\"])\n",
    "    # print(f\"labels shape: {labels.shape}\")\n",
    "    pred_targets = torch.Tensor(pred_targets).long()\n",
    "    # print(f\"pred_targets shape: {pred_targets.shape}\")\n",
    "    # print(f\"idxs: {idxs}\")\n",
    "    \n",
    "            \n",
    "    sequences = torch.stack(sequences)\n",
    "   # print(f\"sequences shape: {sequences.shape}\")\n",
    "    sequences = sequences.view(-1, x.shape[2])\n",
    "    # print(f\"final sequences shape: {sequences.shape}\")\n",
    "    return sequences, labels, pred_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48, 48, 48, 48, 48, 39, 39, 39, 39, 39, 21, 21, 21, 21, 21, 23, 23, 23,\n",
       "        23, 23, 52, 52, 52, 52, 52], dtype=torch.int32)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, :5].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"num_cls\": 5,\n",
    "    \"num_samples\": 3\n",
    "}\n",
    "seqs, labels, targets = seq_batch(opt, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 3, 1, 2])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, tr_iter, model, optim, val_dataloader=None):\n",
    "    if val_dataloader is None:\n",
    "        best_state = None\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    best_acc = 0\n",
    "\n",
    "    #best_model_path = os.path.join(opt.exp, 'best_model.pth')\n",
    "    #last_model_path = os.path.join(opt.exp, 'last_model.pth')\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(opt[\"epochs\"]):\n",
    "        print('=== Epoch: {} ==='.format(epoch))\n",
    "        # tr_iter = iter(tr_dataloader)\n",
    "        print(\"Putting model into train mode...\")\n",
    "        model.train()\n",
    "        print(\"Model is ready to train!\")\n",
    "        if opt[\"cuda\"]:\n",
    "            model = model.cuda()\n",
    "        for batch in tqdm(tr_iter):\n",
    "            optim.zero_grad()\n",
    "            x, y = batch\n",
    "            \n",
    "            # process batch\n",
    "            x, y, last_targets = seq_batch(opt, x, y)\n",
    "\n",
    "            model_output = model(x, y)\n",
    "            # print(f\"shape after model: model_output -> {model_output.shape}\")\n",
    "            last_model = model_output[:, -1, :]\n",
    "            # print(f\"shape after model: last_model -> {last_model.shape}\")\n",
    "            loss = loss_fn(last_model, last_targets)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(get_acc(last_model, last_targets))\n",
    "            \n",
    "        avg_loss = np.mean(train_loss[-opt[\"iterations\"]:])\n",
    "        avg_acc = np.mean(train_acc[-opt[\"iterations\"]:])\n",
    "        print('Avg Train Loss: {}, Avg Train Acc: {}'.format(avg_loss, avg_acc))\n",
    "        if val_dataloader is None:\n",
    "            continue\n",
    "        val_iter = iter(val_dataloader)\n",
    "        model.eval()\n",
    "        for batch in val_iter:\n",
    "            x, y = batch\n",
    "            x, y, last_targets = batch_for_few_shot(opt, x, y)\n",
    "            model_output = model(x, y)\n",
    "            last_model = model_output[:, -1, :]\n",
    "            loss = loss_fn(last_model, last_targets)\n",
    "            val_loss.append(loss.item())\n",
    "            val_acc.append(get_acc(last_model, last_targets))\n",
    "        avg_loss = np.mean(val_loss[-opt[\"iterations\"]:])\n",
    "        avg_acc = np.mean(val_acc[-opt[\"iterations\"]:])\n",
    "        postfix = ' (Best)' if avg_acc >= best_acc else ' (Best: {})'.format(\n",
    "            best_acc)\n",
    "        print('Avg Val Loss: {}, Avg Val Acc: {}{}'.format(\n",
    "            avg_loss, avg_acc, postfix))\n",
    "        if avg_acc >= best_acc:\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            best_acc = avg_acc\n",
    "            best_state = model.state_dict()\n",
    "        #for name in ['train_loss', 'train_acc', 'val_loss', 'val_acc']:\n",
    "        #    save_list_to_file(os.path.join(opt.exp, name + '.txt'), locals()[name])\n",
    "\n",
    "    torch.save(model.state_dict(), last_model_path)\n",
    "\n",
    "    return best_state, best_acc, train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([5, 7, 2866]), y shape: torch.Size([5, 7])\n"
     ]
    }
   ],
   "source": [
    "for sample in tr_iter:\n",
    "    x, y = sample\n",
    "    print(f\"x shape: {x.shape}, y shape: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is of shape `n_classes x (n_support + n_query) x input_dim`, y `n_classes x (n_support + n_query)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final num_channels: 1509\n"
     ]
    }
   ],
   "source": [
    "n_classes = 5\n",
    "n_samples = 3\n",
    "lr = 1e-4\n",
    "# backbone = ResNet10()\n",
    "backbone = FCNet(x_dim=x.shape[2])\n",
    "\n",
    "\n",
    "model = SnailFewShot(n_classes, n_samples, backbone)\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n",
      "Putting model into train mode...\n",
      "Model is ready to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:13<00:05,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.5901453609335912, Avg Train Acc: 0.26506849551854067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support_set shape: torch.Size([15, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "seq shape: torch.Size([16, 2866])\n",
      "sequences shape: torch.Size([20, 16, 2866])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m options \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnum_cls\u001b[39m\u001b[39m'\u001b[39m: n_classes,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnum_samples\u001b[39m\u001b[39m'\u001b[39m: n_samples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m res \u001b[39m=\u001b[39m train(opt\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             tr_iter\u001b[39m=\u001b[39;49mtr_iter,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             val_dataloader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             optim\u001b[39m=\u001b[39;49moptim)\n",
      "\u001b[1;32m/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb Cell 37\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_iter:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     x, y, last_targets \u001b[39m=\u001b[39m batch_for_few_shot(opt, x, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     model_output \u001b[39m=\u001b[39m model(x, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maxconti/Desktop/EPFL/MA3/CS502/project/code/project_code.ipynb#X44sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     last_model \u001b[39m=\u001b[39m model_output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'num_cls': n_classes,\n",
    "    'num_samples': n_samples,\n",
    "    'batch_size': 32,\n",
    "    'cuda': False,\n",
    "    'iterations': 10000,\n",
    "    'epochs': 10\n",
    "}\n",
    "\n",
    "res = train(opt=options,\n",
    "            tr_iter=tr_iter,\n",
    "            val_dataloader=val_loader,\n",
    "            model=model,\n",
    "            optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = init_model(options)\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=options.lr)\n",
    "res = train(opt=options,\n",
    "            tr_dataloader=tr_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            model=model,\n",
    "            optim=optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlb_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
